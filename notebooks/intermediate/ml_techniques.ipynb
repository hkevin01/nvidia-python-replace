{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6880aafa",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning with GPU Acceleration\n",
    "\n",
    "This notebook demonstrates intermediate machine learning techniques using GPU acceleration with RAPIDS cuML, including model selection, hyperparameter tuning, and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.preprocessing import StandardScaler\n",
    "from cuml.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "# Create a synthetic dataset\n",
    "n_samples = 100000\n",
    "n_features = 20\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)\n",
    "\n",
    "# Convert to cuDF DataFrame\n",
    "X = cudf.DataFrame(X)\n",
    "y = cudf.Series(y)\n",
    "\n",
    "print(f\"Created dataset with {n_samples:,} samples and {n_features} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6bc1e4",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "Let's train a Random Forest model and evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c076ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create and train the model\n",
    "start = time()\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Training and prediction completed in {time() - start:.2f} seconds\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8fcf12",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "Let's analyze which features are most important for our model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71375509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance scores\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': [f'Feature_{i}' for i in range(n_features)],\n",
    "    'importance': rf.feature_importances_\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c3e1a",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Let's use cross-validation to find the best hyperparameters for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "start = time()\n",
    "\n",
    "# Simple grid search with cross-validation\n",
    "for n_est in param_grid['n_estimators']:\n",
    "    for depth in param_grid['max_depth']:\n",
    "        for min_split in param_grid['min_samples_split']:\n",
    "            rf = RandomForestClassifier(\n",
    "                n_estimators=n_est,\n",
    "                max_depth=depth,\n",
    "                min_samples_split=min_split\n",
    "            )\n",
    "            rf.fit(X_train, y_train)\n",
    "            score = rf.score(X_test, y_test)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {\n",
    "                    'n_estimators': n_est,\n",
    "                    'max_depth': depth,\n",
    "                    'min_samples_split': min_split\n",
    "                }\n",
    "\n",
    "print(f\"Grid search completed in {time() - start:.2f} seconds\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d456e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored intermediate machine learning techniques with GPU acceleration:\n",
    "\n",
    "1. Model training and evaluation with cuML\n",
    "2. Feature importance analysis\n",
    "3. Hyperparameter tuning with grid search\n",
    "\n",
    "These techniques demonstrate significant speedup compared to CPU-based implementations, especially with larger datasets."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
